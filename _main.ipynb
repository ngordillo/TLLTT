{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f6a48b-bab3-4333-abf3-07711e94b616",
   "metadata": {},
   "source": [
    "# This Looks Like That There\n",
    "\n",
    "Main training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bf3dd4-d4af-4c8c-89f6-67097628c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import imp #imp.reload(module)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from icecream import ic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import network\n",
    "import experiment_settings \n",
    "import data_functions\n",
    "import push_prototypes\n",
    "import plots\n",
    "import common_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e0dba3-9a8a-4d45-b00b-7aaface5fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Elizabeth A. Barnes and Randal J Barnes\"\n",
    "__version__ = \"1 December 2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18825d5a-a951-4a29-8dbd-1b1956974b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.facecolor'] = 'white'\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "dpiFig = 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce58c40-dd37-43ea-9ad3-6d6b56b7d166",
   "metadata": {},
   "source": [
    "## Print the detailed system info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e923341-795f-428a-b5bf-d8cafdce1bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version = 3.9.12 (main, Apr  5 2022, 01:53:17) \n",
      "[Clang 12.0.0 ]\n",
      "numpy version = 1.21.5\n",
      "tensorflow version = 2.9.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"python version = {sys.version}\")\n",
    "print(f\"numpy version = {np.__version__}\")\n",
    "print(f\"tensorflow version = {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b515327-ece1-478c-9c99-0d3979739cbe",
   "metadata": {},
   "source": [
    "## Define experiment settings and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db315d0-951f-4fe1-88b7-168343dfe3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'alas_fourteenday_precip_pre'#'balanced_test'#initial_test'#'mjo'#'quadrants_testcase'\n",
    "\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)\n",
    "\n",
    "imp.reload(common_functions)\n",
    "model_dir, model_diagnostics_dir, vizualization_dir = common_functions.get_exp_directories(EXP_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c333c24-ae7d-43d3-bc87-09fc8e7d8e89",
   "metadata": {},
   "source": [
    "## Define the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3005d411-649b-484a-8c3e-fc23500e11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED          = settings['random_seed']\n",
    "BATCH_SIZE_PREDICT   = settings['batch_size_predict']\n",
    "BATCH_SIZE           = settings['batch_size']\n",
    "NLAYERS              = settings['nlayers']\n",
    "NFILTERS             = settings['nfilters']   \n",
    "assert(len(NFILTERS)==NLAYERS)\n",
    "\n",
    "NCLASSES             = settings['nclasses']\n",
    "PROTOTYPES_PER_CLASS = settings['prototypes_per_class']\n",
    "NPROTOTYPES          = np.sum(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "NEPOCHS              = settings['nepochs']\n",
    "LR_INIT              = settings['lr']\n",
    "LR_CALLBACK_EPOCH    = settings['lr_cb_epoch']\n",
    "PATIENCE             = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab2e28-c92f-4c2d-a5d2-96dcfd9625a3",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb857807-8efc-485b-8be6-29751f6a4e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(RANDOM_SEED)\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521a7140-1796-429f-ad34-1ff25ecca436",
   "metadata": {},
   "source": [
    "## Get and process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f94434b-18eb-408a-8810-af9f27cdf522",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(data_functions)\n",
    "DATA_NAME = settings['data_name']\n",
    "DATA_DIR = settings['data_dir']\n",
    "\n",
    "# print(data_functions)\n",
    "\n",
    "# if(EXP_NAME[:3]=='mjo'):\n",
    "\n",
    "#     labels, data, lat, lon, time = data_functions.load_mjo_data(DATA_DIR)\n",
    "#     X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_mjo_data(labels,\n",
    "#                                                                                          data,\n",
    "#                                                                                          time,\n",
    "#                                                                                          rng, \n",
    "#                                                                                          colored=settings['colored'],\n",
    "#                                                                                          standardize=settings['standardize'],\n",
    "#                                                                                          shuffle=settings['shuffle'],\n",
    "#                                                                                         )        \n",
    "if(EXP_NAME[:9]=='quadrants'):\n",
    "    filename = DATA_DIR + DATA_NAME + '.mat'\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test, lat, lon = data_functions.get_and_process_data(filename, \n",
    "                                                                                        rng, \n",
    "                                                                                        colored=settings['colored'],\n",
    "                                                                                        standardize=settings['standardize'],\n",
    "                                                                                        shuffle=settings['shuffle'],\n",
    "                                                                                        )      \n",
    "elif((EXP_NAME[:12]=='initial_test') or (EXP_NAME[:12]=='smaller_test') or (EXP_NAME[:13]=='balanced_test') or (EXP_NAME[:13]=='threeday_test') or (EXP_NAME[:12]=='zeroday_test') or (EXP_NAME[:16]=='fourteenday_test') or (EXP_NAME[:18]=='fourteenday_precip')\n",
    "     or (EXP_NAME[:19]=='seventeenday_precip') or (EXP_NAME[:16]=='elevenday_precip') or (EXP_NAME[:30]=='fixed_fourteenday_precip') or (EXP_NAME[:30]=='cold_fourteenday_precip') or (EXP_NAME[:30]=='mjo_fourteenday_precip') or (EXP_NAME[:30]=='shuffle_fourteenday_precip')\n",
    "     or (EXP_NAME[:30]=='cali_fourteenday_precip') or (EXP_NAME[:30]=='alas_fourteenday_precip') or (EXP_NAME[:30]=='alas_fourteenday_5proto') or (EXP_NAME[:30]=='alas_fourteenday_back') or (EXP_NAME[:30]=='alas_fourteenday_large') or (EXP_NAME[:30]=='vanc_fourteenday_precip')\n",
    "     or (EXP_NAME[:30]=='alas_fourteenday_precip_pre')):\n",
    "    print(settings['shuffle'])\n",
    "    labels, data, lat, lon, time = data_functions.load_pres_data(DATA_DIR)\n",
    "    X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_pres_data(labels,\n",
    "                                                                                         data,\n",
    "                                                                                         time,\n",
    "                                                                                         rng, \n",
    "                                                                                         colored=settings['colored'],\n",
    "                                                                                         standardize=settings['standardize'],\n",
    "                                                                                         shuffle=settings['shuffle'],\n",
    "                                                                                        )\n",
    "elif((EXP_NAME[:21]=='fourteenday_both_test') or ((EXP_NAME[:18]=='threeday_both_test'))):\n",
    "    print(\"bingo\")\n",
    "    labels, data, lat, lon, time = data_functions.load_z500_precip_data(DATA_DIR)\n",
    "    X_train, y_train, time_train, X_val, y_val, time_val, X_test, y_test, time_test = data_functions.get_and_process_pres_data(labels,\n",
    "                                                                                         data,\n",
    "                                                                                         time,\n",
    "                                                                                         rng, \n",
    "                                                                                         colored=settings['colored'],\n",
    "                                                                                         standardize=settings['standardize'],\n",
    "                                                                                         shuffle=settings['shuffle'],\n",
    "                                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b621855-61ee-4e16-9948-9f2bcf61721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "proto_class_mask = network.createClassIdentity(PROTOTYPES_PER_CLASS)\n",
    "\n",
    "prototypes_of_correct_class_train = np.zeros((len(y_train),NPROTOTYPES))\n",
    "for i in range(0,prototypes_of_correct_class_train.shape[0]):\n",
    "    prototypes_of_correct_class_train[i,:] = proto_class_mask[:,int(y_train[i])]\n",
    "    \n",
    "prototypes_of_correct_class_val   = np.zeros((len(y_val),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_val.shape[0]):\n",
    "    prototypes_of_correct_class_val[i,:] = proto_class_mask[:,int(y_val[i])]\n",
    "\n",
    "prototypes_of_correct_class_test   = np.zeros((len(y_test),NPROTOTYPES))    \n",
    "for i in range(0,prototypes_of_correct_class_test.shape[0]):\n",
    "    prototypes_of_correct_class_test[i,:] = proto_class_mask[:,int(y_test[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2b2787-9d90-4955-90a4-1a6526c918e9",
   "metadata": {},
   "source": [
    "## Define the training callbacks and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64ca24eb-ab9c-4db0-82c8-94980521c597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 14:50:35.135376: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# callbacks\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < LR_CALLBACK_EPOCH:\n",
    "        return np.round(lr,8)\n",
    "    else:\n",
    "        if(epoch % 2 == 0):\n",
    "            return lr/2.\n",
    "        else:\n",
    "            return lr\n",
    "\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)    \n",
    "    \n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_sparse_categorical_accuracy', \n",
    "    mode='max',\n",
    "    patience=settings['patience'], \n",
    "    restore_best_weights=True, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "callbacks_list = [\n",
    "#     lr_callback,\n",
    "#     es_callback,\n",
    "]            \n",
    "\n",
    "# metrics\n",
    "metrics_list = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa63e6-adc0-40b0-92a1-16dd4cc806f6",
   "metadata": {},
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c87cc2fb-5cf9-4029-824c-c24262ccb729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[16, 16, 16]\n",
      "(64, 209, 1)\n",
      "3\n",
      "[10, 10, 10]\n",
      "30\n",
      "False\n",
      "0.2\n",
      "-0.02\n",
      "0.1\n",
      "-0.5\n",
      "False\n",
      "8\n",
      "64\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "False\n",
      "Model: \"full_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, 64, 209, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv_0 (Conv2D)                (None, 64, 209, 16)  160         ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64, 209, 16)  0           ['conv_0[0][0]']                 \n",
      "                                                                                                  \n",
      " maxpooling_0 (AveragePooling2D  (None, 32, 104, 16)  0          ['dropout[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 32, 104, 16)  2320        ['maxpooling_0[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 104, 16)  0           ['conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " maxpooling_1 (AveragePooling2D  (None, 16, 52, 16)  0           ['dropout_1[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 16, 52, 16)   2320        ['maxpooling_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 52, 16)   0           ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " maxpooling_2 (AveragePooling2D  (None, 8, 26, 16)   0           ['dropout_2[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " first_1x1_conv (Conv2D)        (None, 8, 26, 64)    1088        ['maxpooling_2[0][0]']           \n",
      "                                                                                                  \n",
      " second_1x1_conv (Conv2D)       (None, 8, 26, 64)    4160        ['first_1x1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " prototypes_of_correct_class (I  [(None, 30)]        0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " prototype (Prototype)          (None, 30)           8160        ['second_1x1_conv[0][0]',        \n",
      "                                                                  'prototypes_of_correct_class[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " final_weights (FinalWeights)   (None, 3)            90          ['prototype[0][0]']              \n",
      "                                                                                                  \n",
      " softmax_output (Softmax)       (None, 3)            0           ['final_weights[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,298\n",
      "Trainable params: 18,298\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "__ = imp.reload(network)\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = network.build_model(\n",
    "    nlayers              = NLAYERS,\n",
    "    nfilters             = NFILTERS,\n",
    "    input_shape          = X_train.shape[1:],\n",
    "    output_shape         = NCLASSES,\n",
    "    prototypes_per_class = PROTOTYPES_PER_CLASS,\n",
    "    network_seed         = RANDOM_SEED,    \n",
    "    prototype_channels   = settings['prototype_channels'],    \n",
    "    coeff_cluster        = settings['coeff_cluster'],\n",
    "    coeff_separation     = settings['coeff_separation'],\n",
    "    coeff_l1             = settings['coeff_l1'],\n",
    "    incorrect_strength   = settings['incorrect_strength'],\n",
    "    double_conv          = settings['double_conv'],\n",
    "    kernel_l1_coeff      = 0.0,#settings['kernel_l1_coeff'],\n",
    "    kernel_l2_coeff      = 0.0,#settings['kernel_l2_coeff'],\n",
    "    drop_rate            = 0.0,\n",
    "    drop_rate_final      = 0.0,        \n",
    "    \n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404175a3-bc7c-4f2e-8445-3985983c8458",
   "metadata": {},
   "source": [
    "## Load pre-trained weights into convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8dbbe1c-cf25-489c-898a-905a537609af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained convolutional layers from ./saved_models/vanc_fourteenday_precip/pretrained_model_vanc_fourteenday_precip\n",
      "   loading pretrained weights for --> conv_0\n",
      "   loading pretrained weights for --> conv_1\n",
      "   loading pretrained weights for --> conv_2\n"
     ]
    }
   ],
   "source": [
    "if(settings['pretrain'] == True):\n",
    "\n",
    "    if(settings['pretrain_exp'] is None):\n",
    "        PRETRAINED_MODEL = model_dir + 'pretrained_model_' + EXP_NAME \n",
    "    else:\n",
    "        PRETRAINED_MODEL = './saved_models/' + settings['pretrain_exp'] \n",
    "\n",
    "    print('loading pretrained convolutional layers from ' + PRETRAINED_MODEL)\n",
    "    pretrained_model = tf.keras.models.load_model(PRETRAINED_MODEL)\n",
    "\n",
    "    for layer in range(1,len(model.layers)):\n",
    "        if(model.layers[layer].name[:4]=='conv'):\n",
    "            print('   loading pretrained weights for --> ' + model.layers[layer].name)\n",
    "            model.layers[layer].set_weights(pretrained_model.layers[layer].get_weights())\n",
    "else:\n",
    "    print('no pretrained model specified. keeping random initialized weights.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1e13996-3403-43f2-9544-173155b4ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError('here')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5c00a-658f-4597-a2fe-57e838c1db8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b26f9-6628-4c46-b1d3-dda086aa468f",
   "metadata": {},
   "source": [
    "# Run Training Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ab06f5d-7264-4ec3-ba4b-b29712e442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.reload(network)\n",
    "imp.reload(plots)\n",
    "imp.reload(push_prototypes)\n",
    "imp.reload(experiment_settings)\n",
    "settings = experiment_settings.get_settings(EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e32234e-5283-48e5-8024-d1fd279e80b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.shape(X_train): (25550, 64, 209, 1)\n",
      "ic| np.shape(prototypes_of_correct_class_train): (25550, 30)\n",
      "ic| np.shape(prototypes_of_correct_class_train): (25550, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25550, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(np.shape(X_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))\n",
    "ic(np.shape(prototypes_of_correct_class_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "933b03cd-4810-4c70-b8fa-3fb05caa3e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): 0.0\n",
      "    np.max(model.layers[-3].get_weights()[1]): 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 0\n",
      "--------------------\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   conv_2 --> False\n",
      "   maxpooling_2 --> False\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 49s 60ms/step - loss: 4.2259 - sparse_categorical_accuracy: 0.3509 - cluster_cost: 0.5575 - separation_cost: 0.4958 - l1_weights_cost: 3.0000 - val_loss: 4.1682 - val_sparse_categorical_accuracy: 0.3591 - val_cluster_cost: 0.2996 - val_separation_cost: 0.2801 - val_l1_weights_cost: 3.0000\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 37s 47ms/step - loss: 4.1681 - sparse_categorical_accuracy: 0.3459 - cluster_cost: 0.2513 - separation_cost: 0.2321 - l1_weights_cost: 3.0000 - val_loss: 4.1552 - val_sparse_categorical_accuracy: 0.3464 - val_cluster_cost: 0.2430 - val_separation_cost: 0.2329 - val_l1_weights_cost: 3.0000\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 38s 48ms/step - loss: 4.1509 - sparse_categorical_accuracy: 0.3547 - cluster_cost: 0.2037 - separation_cost: 0.1918 - l1_weights_cost: 3.0000 - val_loss: 4.1275 - val_sparse_categorical_accuracy: 0.3649 - val_cluster_cost: 0.1568 - val_separation_cost: 0.1532 - val_l1_weights_cost: 3.0000\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 41s 51ms/step - loss: 4.1408 - sparse_categorical_accuracy: 0.3596 - cluster_cost: 0.1731 - separation_cost: 0.1639 - l1_weights_cost: 3.0000 - val_loss: 4.1706 - val_sparse_categorical_accuracy: 0.3676 - val_cluster_cost: 0.1753 - val_separation_cost: 0.1582 - val_l1_weights_cost: 3.0000\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 38s 47ms/step - loss: 4.1387 - sparse_categorical_accuracy: 0.3669 - cluster_cost: 0.1703 - separation_cost: 0.1612 - l1_weights_cost: 3.0000 - val_loss: 4.1551 - val_sparse_categorical_accuracy: 0.3423 - val_cluster_cost: 0.1878 - val_separation_cost: 0.1766 - val_l1_weights_cost: 3.0000\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 36s 45ms/step - loss: 4.1322 - sparse_categorical_accuracy: 0.3724 - cluster_cost: 0.1680 - separation_cost: 0.1599 - l1_weights_cost: 3.0000 - val_loss: 4.1317 - val_sparse_categorical_accuracy: 0.3644 - val_cluster_cost: 0.1620 - val_separation_cost: 0.1557 - val_l1_weights_cost: 3.0000\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 36s 45ms/step - loss: 4.1292 - sparse_categorical_accuracy: 0.3742 - cluster_cost: 0.1561 - separation_cost: 0.1485 - l1_weights_cost: 3.0000 - val_loss: 4.1136 - val_sparse_categorical_accuracy: 0.3807 - val_cluster_cost: 0.1414 - val_separation_cost: 0.1385 - val_l1_weights_cost: 3.0000\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 36s 45ms/step - loss: 4.1266 - sparse_categorical_accuracy: 0.3798 - cluster_cost: 0.1555 - separation_cost: 0.1484 - l1_weights_cost: 3.0000 - val_loss: 4.1351 - val_sparse_categorical_accuracy: 0.3654 - val_cluster_cost: 0.1579 - val_separation_cost: 0.1489 - val_l1_weights_cost: 3.0000\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 36s 45ms/step - loss: 4.1217 - sparse_categorical_accuracy: 0.3849 - cluster_cost: 0.1492 - separation_cost: 0.1427 - l1_weights_cost: 3.0000 - val_loss: 4.1300 - val_sparse_categorical_accuracy: 0.3804 - val_cluster_cost: 0.1541 - val_separation_cost: 0.1395 - val_l1_weights_cost: 3.0000\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 35s 44ms/step - loss: 4.1197 - sparse_categorical_accuracy: 0.3869 - cluster_cost: 0.1487 - separation_cost: 0.1416 - l1_weights_cost: 3.0000 - val_loss: 4.1623 - val_sparse_categorical_accuracy: 0.3727 - val_cluster_cost: 0.1375 - val_separation_cost: 0.1286 - val_l1_weights_cost: 3.0000\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 1\n",
      "--------------------\n",
      "Running Prototype Push\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 15:00:51.380346: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage0: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage0; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 437ms/step\n",
      "9/9 [==============================] - 4s 416ms/step\n",
      "9/9 [==============================] - 5s 470ms/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   conv_2 --> False\n",
      "   maxpooling_2 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.2441067\n",
      "    np.max(model.layers[-3].get_weights()[1]): 1.8554245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 39s 48ms/step - loss: 4.3776 - sparse_categorical_accuracy: 0.3695 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.6276 - val_loss: 1.3543 - val_sparse_categorical_accuracy: 0.3485 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.1222\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 29s 37ms/step - loss: 1.3235 - sparse_categorical_accuracy: 0.3568 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0563 - val_loss: 1.2431 - val_sparse_categorical_accuracy: 0.3441 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0285\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 31s 39ms/step - loss: 1.2631 - sparse_categorical_accuracy: 0.3551 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0238 - val_loss: 1.2645 - val_sparse_categorical_accuracy: 0.3445 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0266\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 29s 37ms/step - loss: 1.2652 - sparse_categorical_accuracy: 0.3554 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0238 - val_loss: 1.2654 - val_sparse_categorical_accuracy: 0.3566 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0276\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 33s 42ms/step - loss: 1.2479 - sparse_categorical_accuracy: 0.3583 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0238 - val_loss: 1.6536 - val_sparse_categorical_accuracy: 0.3352 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0278\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 33s 41ms/step - loss: 1.2352 - sparse_categorical_accuracy: 0.3566 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0231 - val_loss: 1.2943 - val_sparse_categorical_accuracy: 0.3370 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0253\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 33s 41ms/step - loss: 1.2321 - sparse_categorical_accuracy: 0.3526 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0230 - val_loss: 1.1565 - val_sparse_categorical_accuracy: 0.3516 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0256\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 33s 42ms/step - loss: 1.2490 - sparse_categorical_accuracy: 0.3556 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0241 - val_loss: 1.4320 - val_sparse_categorical_accuracy: 0.3269 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0234\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 31s 39ms/step - loss: 1.2280 - sparse_categorical_accuracy: 0.3581 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0239 - val_loss: 1.2768 - val_sparse_categorical_accuracy: 0.3346 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0233\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.2369 - sparse_categorical_accuracy: 0.3539 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0238 - val_loss: 1.1658 - val_sparse_categorical_accuracy: 0.3470 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0201\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage1/assets\n",
      "2022-10-17 15:06:52.152143: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage1: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage1; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.2441067\n",
      "    np.max(model.layers[-3].get_weights()[1]): 1.8554245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 2\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   conv_2 --> True\n",
      "   maxpooling_2 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.01\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 98s 120ms/step - loss: 1.1185 - sparse_categorical_accuracy: 0.3603 - cluster_cost: 0.0213 - separation_cost: 0.0134 - l1_weights_cost: 0.0201 - val_loss: 1.1211 - val_sparse_categorical_accuracy: 0.3671 - val_cluster_cost: 0.0358 - val_separation_cost: 0.0267 - val_l1_weights_cost: 0.0201\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 86s 108ms/step - loss: 1.1171 - sparse_categorical_accuracy: 0.3746 - cluster_cost: 0.0225 - separation_cost: 0.0115 - l1_weights_cost: 0.0201 - val_loss: 1.1176 - val_sparse_categorical_accuracy: 0.3837 - val_cluster_cost: 0.0220 - val_separation_cost: 0.0124 - val_l1_weights_cost: 0.0201\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 82s 103ms/step - loss: 1.1157 - sparse_categorical_accuracy: 0.3748 - cluster_cost: 0.0182 - separation_cost: 0.0110 - l1_weights_cost: 0.0201 - val_loss: 1.1103 - val_sparse_categorical_accuracy: 0.3837 - val_cluster_cost: 0.0176 - val_separation_cost: 0.0130 - val_l1_weights_cost: 0.0201\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 87s 109ms/step - loss: 1.1131 - sparse_categorical_accuracy: 0.3839 - cluster_cost: 0.0171 - separation_cost: 0.0103 - l1_weights_cost: 0.0201 - val_loss: 1.1116 - val_sparse_categorical_accuracy: 0.3912 - val_cluster_cost: 0.0226 - val_separation_cost: 0.0190 - val_l1_weights_cost: 0.0201\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 83s 104ms/step - loss: 1.1136 - sparse_categorical_accuracy: 0.3822 - cluster_cost: 0.0209 - separation_cost: 0.0133 - l1_weights_cost: 0.0201 - val_loss: 1.1132 - val_sparse_categorical_accuracy: 0.3791 - val_cluster_cost: 0.0225 - val_separation_cost: 0.0170 - val_l1_weights_cost: 0.0201\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 82s 103ms/step - loss: 1.1111 - sparse_categorical_accuracy: 0.3909 - cluster_cost: 0.0212 - separation_cost: 0.0136 - l1_weights_cost: 0.0201 - val_loss: 1.1149 - val_sparse_categorical_accuracy: 0.3812 - val_cluster_cost: 0.0223 - val_separation_cost: 0.0129 - val_l1_weights_cost: 0.0201\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 80s 100ms/step - loss: 1.1101 - sparse_categorical_accuracy: 0.3904 - cluster_cost: 0.0201 - separation_cost: 0.0134 - l1_weights_cost: 0.0201 - val_loss: 1.1112 - val_sparse_categorical_accuracy: 0.3898 - val_cluster_cost: 0.0095 - val_separation_cost: 0.0077 - val_l1_weights_cost: 0.0201\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 85s 106ms/step - loss: 1.1108 - sparse_categorical_accuracy: 0.3911 - cluster_cost: 0.0202 - separation_cost: 0.0141 - l1_weights_cost: 0.0201 - val_loss: 1.1155 - val_sparse_categorical_accuracy: 0.3684 - val_cluster_cost: 0.0170 - val_separation_cost: 0.0135 - val_l1_weights_cost: 0.0201\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 93s 117ms/step - loss: 1.1071 - sparse_categorical_accuracy: 0.3992 - cluster_cost: 0.0148 - separation_cost: 0.0107 - l1_weights_cost: 0.0201 - val_loss: 1.1078 - val_sparse_categorical_accuracy: 0.3972 - val_cluster_cost: 0.0151 - val_separation_cost: 0.0110 - val_l1_weights_cost: 0.0201\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 82s 103ms/step - loss: 1.1100 - sparse_categorical_accuracy: 0.3894 - cluster_cost: 0.0195 - separation_cost: 0.0135 - l1_weights_cost: 0.0201 - val_loss: 1.1130 - val_sparse_categorical_accuracy: 0.3797 - val_cluster_cost: 0.0106 - val_separation_cost: 0.0072 - val_l1_weights_cost: 0.0201\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 3\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 15:21:24.017229: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage2: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage2; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Prototype Push\n",
      "9/9 [==============================] - 6s 557ms/step\n",
      "9/9 [==============================] - 5s 434ms/step\n",
      "9/9 [==============================] - 7s 544ms/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   conv_2 --> False\n",
      "   maxpooling_2 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6016492\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.031141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 44s 53ms/step - loss: 1.7943 - sparse_categorical_accuracy: 0.3636 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0308 - val_loss: 2.0597 - val_sparse_categorical_accuracy: 0.3232 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0265\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.8014 - sparse_categorical_accuracy: 0.3450 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0265 - val_loss: 1.4235 - val_sparse_categorical_accuracy: 0.3208 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0234\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 29s 37ms/step - loss: 1.7169 - sparse_categorical_accuracy: 0.3489 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0252 - val_loss: 1.2744 - val_sparse_categorical_accuracy: 0.3296 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0233\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 29s 36ms/step - loss: 1.7345 - sparse_categorical_accuracy: 0.3514 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0248 - val_loss: 1.7533 - val_sparse_categorical_accuracy: 0.3550 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0302\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 29s 36ms/step - loss: 1.6112 - sparse_categorical_accuracy: 0.3488 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0254 - val_loss: 1.7304 - val_sparse_categorical_accuracy: 0.3448 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0273\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 29s 37ms/step - loss: 1.7651 - sparse_categorical_accuracy: 0.3588 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0267 - val_loss: 1.4304 - val_sparse_categorical_accuracy: 0.3493 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0251\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 29s 36ms/step - loss: 1.8008 - sparse_categorical_accuracy: 0.3475 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0272 - val_loss: 1.8438 - val_sparse_categorical_accuracy: 0.3487 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0253\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.7139 - sparse_categorical_accuracy: 0.3525 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0248 - val_loss: 2.5545 - val_sparse_categorical_accuracy: 0.3303 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0265\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 32s 40ms/step - loss: 1.7199 - sparse_categorical_accuracy: 0.3489 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0268 - val_loss: 1.5001 - val_sparse_categorical_accuracy: 0.3558 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0262\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 34s 42ms/step - loss: 1.8197 - sparse_categorical_accuracy: 0.3483 - cluster_cost: 0.0000e+00 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0278 - val_loss: 1.6572 - val_sparse_categorical_accuracy: 0.3519 - val_cluster_cost: 0.0000e+00 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0250\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage3/assets\n",
      "2022-10-17 15:27:25.290908: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage3: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage3; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6016492\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.031141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 4\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   conv_2 --> True\n",
      "   maxpooling_2 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 0.001\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 98s 120ms/step - loss: 1.1333 - sparse_categorical_accuracy: 0.3708 - cluster_cost: 0.0070 - separation_cost: 0.0041 - l1_weights_cost: 0.0250 - val_loss: 1.1210 - val_sparse_categorical_accuracy: 0.3774 - val_cluster_cost: 0.0074 - val_separation_cost: 0.0041 - val_l1_weights_cost: 0.0250\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 83s 103ms/step - loss: 1.1146 - sparse_categorical_accuracy: 0.3895 - cluster_cost: 0.0061 - separation_cost: 0.0028 - l1_weights_cost: 0.0250 - val_loss: 1.1160 - val_sparse_categorical_accuracy: 0.3814 - val_cluster_cost: 0.0063 - val_separation_cost: 0.0020 - val_l1_weights_cost: 0.0250\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 84s 105ms/step - loss: 1.1107 - sparse_categorical_accuracy: 0.3930 - cluster_cost: 0.0034 - separation_cost: 0.0014 - l1_weights_cost: 0.0250 - val_loss: 1.1133 - val_sparse_categorical_accuracy: 0.3826 - val_cluster_cost: 0.0014 - val_separation_cost: 7.2354e-04 - val_l1_weights_cost: 0.0250\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 85s 106ms/step - loss: 1.1077 - sparse_categorical_accuracy: 0.3982 - cluster_cost: 0.0017 - separation_cost: 9.0066e-04 - l1_weights_cost: 0.0250 - val_loss: 1.1112 - val_sparse_categorical_accuracy: 0.3905 - val_cluster_cost: 0.0012 - val_separation_cost: 2.0752e-04 - val_l1_weights_cost: 0.0250\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 82s 102ms/step - loss: 1.1066 - sparse_categorical_accuracy: 0.3994 - cluster_cost: 0.0016 - separation_cost: 9.0281e-04 - l1_weights_cost: 0.0250 - val_loss: 1.1125 - val_sparse_categorical_accuracy: 0.3853 - val_cluster_cost: 5.3137e-04 - val_separation_cost: 3.5467e-05 - val_l1_weights_cost: 0.0250\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 80s 100ms/step - loss: 1.1055 - sparse_categorical_accuracy: 0.4023 - cluster_cost: 0.0020 - separation_cost: 0.0012 - l1_weights_cost: 0.0250 - val_loss: 1.1101 - val_sparse_categorical_accuracy: 0.3914 - val_cluster_cost: 0.0021 - val_separation_cost: 0.0012 - val_l1_weights_cost: 0.0250\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 82s 102ms/step - loss: 1.1040 - sparse_categorical_accuracy: 0.4081 - cluster_cost: 0.0021 - separation_cost: 0.0012 - l1_weights_cost: 0.0250 - val_loss: 1.1097 - val_sparse_categorical_accuracy: 0.3904 - val_cluster_cost: 0.0025 - val_separation_cost: 0.0019 - val_l1_weights_cost: 0.0250\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 77s 97ms/step - loss: 1.1032 - sparse_categorical_accuracy: 0.4054 - cluster_cost: 0.0018 - separation_cost: 0.0011 - l1_weights_cost: 0.0250 - val_loss: 1.1100 - val_sparse_categorical_accuracy: 0.3890 - val_cluster_cost: 0.0022 - val_separation_cost: 0.0012 - val_l1_weights_cost: 0.0250\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 78s 98ms/step - loss: 1.1025 - sparse_categorical_accuracy: 0.4099 - cluster_cost: 0.0018 - separation_cost: 0.0011 - l1_weights_cost: 0.0250 - val_loss: 1.1106 - val_sparse_categorical_accuracy: 0.3896 - val_cluster_cost: 0.0017 - val_separation_cost: 0.0013 - val_l1_weights_cost: 0.0250\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 87s 109ms/step - loss: 1.1019 - sparse_categorical_accuracy: 0.4068 - cluster_cost: 0.0017 - separation_cost: 0.0012 - l1_weights_cost: 0.0250 - val_loss: 1.1075 - val_sparse_categorical_accuracy: 0.3968 - val_cluster_cost: 0.0025 - val_separation_cost: 0.0018 - val_l1_weights_cost: 0.0250\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 5\n",
      "--------------------\n",
      "Running Prototype Push\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 15:41:34.176169: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage4: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage4; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 8s 596ms/step\n",
      "9/9 [==============================] - 7s 554ms/step\n",
      "9/9 [==============================] - 10s 929ms/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   conv_2 --> False\n",
      "   maxpooling_2 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6116372\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.0081964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 45s 55ms/step - loss: 1.1176 - sparse_categorical_accuracy: 0.3943 - cluster_cost: 3.0880e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0069 - val_loss: 1.2168 - val_sparse_categorical_accuracy: 0.3701 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0059\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 31s 39ms/step - loss: 1.1266 - sparse_categorical_accuracy: 0.3922 - cluster_cost: 3.0905e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0056 - val_loss: 1.2520 - val_sparse_categorical_accuracy: 0.3574 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0064\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.1123 - sparse_categorical_accuracy: 0.3946 - cluster_cost: 3.0930e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0052 - val_loss: 1.1028 - val_sparse_categorical_accuracy: 0.3953 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0054\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 31s 38ms/step - loss: 1.1170 - sparse_categorical_accuracy: 0.3899 - cluster_cost: 3.0905e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0055 - val_loss: 1.1628 - val_sparse_categorical_accuracy: 0.3744 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0066\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.1173 - sparse_categorical_accuracy: 0.3894 - cluster_cost: 3.0880e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0053 - val_loss: 1.1250 - val_sparse_categorical_accuracy: 0.3822 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0059\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.1213 - sparse_categorical_accuracy: 0.3955 - cluster_cost: 3.0880e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0053 - val_loss: 1.1023 - val_sparse_categorical_accuracy: 0.3741 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0047\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.1143 - sparse_categorical_accuracy: 0.3917 - cluster_cost: 3.0880e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0054 - val_loss: 1.1005 - val_sparse_categorical_accuracy: 0.3947 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0050\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 29s 37ms/step - loss: 1.1180 - sparse_categorical_accuracy: 0.3931 - cluster_cost: 3.0880e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0056 - val_loss: 1.1277 - val_sparse_categorical_accuracy: 0.3880 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0060\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.1149 - sparse_categorical_accuracy: 0.3915 - cluster_cost: 3.0905e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0053 - val_loss: 1.1042 - val_sparse_categorical_accuracy: 0.3681 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0048\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.1166 - sparse_categorical_accuracy: 0.3939 - cluster_cost: 3.0880e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0053 - val_loss: 1.1103 - val_sparse_categorical_accuracy: 0.3862 - val_cluster_cost: 3.3014e-05 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0056\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage5/assets\n",
      "2022-10-17 15:47:55.539244: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage5: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage5; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6116372\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.0081964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 6\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   conv_2 --> True\n",
      "   maxpooling_2 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 1e-04\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 90s 111ms/step - loss: 1.0819 - sparse_categorical_accuracy: 0.4008 - cluster_cost: 1.6916e-04 - separation_cost: 4.6186e-05 - l1_weights_cost: 0.0056 - val_loss: 1.0927 - val_sparse_categorical_accuracy: 0.3925 - val_cluster_cost: 4.4284e-04 - val_separation_cost: 2.0535e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 80s 100ms/step - loss: 1.0803 - sparse_categorical_accuracy: 0.4121 - cluster_cost: 5.1195e-04 - separation_cost: 2.2658e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0907 - val_sparse_categorical_accuracy: 0.3938 - val_cluster_cost: 6.6292e-04 - val_separation_cost: 3.0702e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 77s 96ms/step - loss: 1.0794 - sparse_categorical_accuracy: 0.4134 - cluster_cost: 6.0408e-04 - separation_cost: 2.4188e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0914 - val_sparse_categorical_accuracy: 0.3912 - val_cluster_cost: 7.0008e-04 - val_separation_cost: 3.2459e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 77s 96ms/step - loss: 1.0791 - sparse_categorical_accuracy: 0.4124 - cluster_cost: 6.5296e-04 - separation_cost: 2.6181e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0903 - val_sparse_categorical_accuracy: 0.3957 - val_cluster_cost: 6.5739e-04 - val_separation_cost: 1.9494e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 76s 95ms/step - loss: 1.0788 - sparse_categorical_accuracy: 0.4138 - cluster_cost: 6.5908e-04 - separation_cost: 2.2786e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0905 - val_sparse_categorical_accuracy: 0.3957 - val_cluster_cost: 6.5774e-04 - val_separation_cost: 1.9448e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 77s 96ms/step - loss: 1.0785 - sparse_categorical_accuracy: 0.4146 - cluster_cost: 6.5389e-04 - separation_cost: 2.0133e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0900 - val_sparse_categorical_accuracy: 0.3982 - val_cluster_cost: 6.9615e-04 - val_separation_cost: 1.9836e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 77s 97ms/step - loss: 1.0783 - sparse_categorical_accuracy: 0.4155 - cluster_cost: 6.5102e-04 - separation_cost: 2.0729e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0903 - val_sparse_categorical_accuracy: 0.3945 - val_cluster_cost: 5.7848e-04 - val_separation_cost: 1.6951e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 85s 107ms/step - loss: 1.0780 - sparse_categorical_accuracy: 0.4155 - cluster_cost: 6.4635e-04 - separation_cost: 1.9767e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0890 - val_sparse_categorical_accuracy: 0.3968 - val_cluster_cost: 7.4485e-04 - val_separation_cost: 2.0143e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 84s 105ms/step - loss: 1.0777 - sparse_categorical_accuracy: 0.4160 - cluster_cost: 7.0253e-04 - separation_cost: 2.1019e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0905 - val_sparse_categorical_accuracy: 0.3973 - val_cluster_cost: 7.0274e-04 - val_separation_cost: 1.9953e-04 - val_l1_weights_cost: 0.0056\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 80s 101ms/step - loss: 1.0776 - sparse_categorical_accuracy: 0.4148 - cluster_cost: 6.8332e-04 - separation_cost: 2.0749e-04 - l1_weights_cost: 0.0056 - val_loss: 1.0893 - val_sparse_categorical_accuracy: 0.3924 - val_cluster_cost: 5.9395e-04 - val_separation_cost: 2.1842e-04 - val_l1_weights_cost: 0.0056\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 7\n",
      "--------------------\n",
      "Running Prototype Push\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 16:01:31.124684: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage6: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage6; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 510ms/step\n",
      "9/9 [==============================] - 6s 501ms/step\n",
      "9/9 [==============================] - 7s 549ms/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   conv_2 --> False\n",
      "   maxpooling_2 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 1e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6167948\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.045758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 45s 55ms/step - loss: 1.0789 - sparse_categorical_accuracy: 0.4046 - cluster_cost: 1.8276e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0026 - val_loss: 1.0925 - val_sparse_categorical_accuracy: 0.3763 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0013\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 33s 42ms/step - loss: 1.0798 - sparse_categorical_accuracy: 0.4119 - cluster_cost: 1.8281e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0890 - val_sparse_categorical_accuracy: 0.3964 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0015\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 29s 36ms/step - loss: 1.0783 - sparse_categorical_accuracy: 0.4128 - cluster_cost: 1.8278e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0842 - val_sparse_categorical_accuracy: 0.3967 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0012\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 33s 41ms/step - loss: 1.0782 - sparse_categorical_accuracy: 0.4100 - cluster_cost: 1.8281e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0014 - val_loss: 1.0844 - val_sparse_categorical_accuracy: 0.4001 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0013\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.0789 - sparse_categorical_accuracy: 0.4119 - cluster_cost: 1.8273e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0895 - val_sparse_categorical_accuracy: 0.3921 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0014\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.0786 - sparse_categorical_accuracy: 0.4142 - cluster_cost: 1.8278e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0014 - val_loss: 1.0837 - val_sparse_categorical_accuracy: 0.4026 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0013\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.0792 - sparse_categorical_accuracy: 0.4114 - cluster_cost: 1.8273e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0880 - val_sparse_categorical_accuracy: 0.3991 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0012\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 36s 45ms/step - loss: 1.0792 - sparse_categorical_accuracy: 0.4100 - cluster_cost: 1.8271e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0841 - val_sparse_categorical_accuracy: 0.3936 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 9.7513e-04\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 33s 41ms/step - loss: 1.0784 - sparse_categorical_accuracy: 0.4119 - cluster_cost: 1.8278e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0014 - val_loss: 1.0896 - val_sparse_categorical_accuracy: 0.3997 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0012\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 30s 37ms/step - loss: 1.0781 - sparse_categorical_accuracy: 0.4148 - cluster_cost: 1.8271e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0861 - val_sparse_categorical_accuracy: 0.4005 - val_cluster_cost: 1.9475e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0015\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage7/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage7/assets\n",
      "2022-10-17 16:07:45.801143: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage7: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage7; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n",
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.6167948\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.045758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 8\n",
      "--------------------\n",
      "   conv_0 --> True\n",
      "   maxpooling_0 --> True\n",
      "   conv_1 --> True\n",
      "   maxpooling_1 --> True\n",
      "   conv_2 --> True\n",
      "   maxpooling_2 --> True\n",
      "   first_1x1_conv --> True\n",
      "   second_1x1_conv --> True\n",
      "   prototype --> True\n",
      "   final_weights --> False\n",
      "learning rate = 1e-05\n",
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 96s 119ms/step - loss: 1.0748 - sparse_categorical_accuracy: 0.4114 - cluster_cost: 1.7997e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0857 - val_sparse_categorical_accuracy: 0.4018 - val_cluster_cost: 1.9491e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0015\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 89s 111ms/step - loss: 1.0744 - sparse_categorical_accuracy: 0.4200 - cluster_cost: 1.8250e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0855 - val_sparse_categorical_accuracy: 0.4021 - val_cluster_cost: 1.9462e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0015\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 85s 106ms/step - loss: 1.0741 - sparse_categorical_accuracy: 0.4202 - cluster_cost: 1.5770e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0854 - val_sparse_categorical_accuracy: 0.4020 - val_cluster_cost: 1.9537e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 0.0015\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 85s 107ms/step - loss: 1.0740 - sparse_categorical_accuracy: 0.4193 - cluster_cost: 1.8446e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0854 - val_sparse_categorical_accuracy: 0.4012 - val_cluster_cost: 2.2122e-04 - val_separation_cost: 2.6723e-08 - val_l1_weights_cost: 0.0015\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 92s 115ms/step - loss: 1.0739 - sparse_categorical_accuracy: 0.4189 - cluster_cost: 2.0313e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0853 - val_sparse_categorical_accuracy: 0.4018 - val_cluster_cost: 2.2068e-04 - val_separation_cost: 2.6723e-08 - val_l1_weights_cost: 0.0015\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 83s 103ms/step - loss: 1.0738 - sparse_categorical_accuracy: 0.4189 - cluster_cost: 2.0560e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0853 - val_sparse_categorical_accuracy: 0.4016 - val_cluster_cost: 2.2066e-04 - val_separation_cost: 2.6723e-08 - val_l1_weights_cost: 0.0015\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 80s 100ms/step - loss: 1.0737 - sparse_categorical_accuracy: 0.4189 - cluster_cost: 1.8911e-04 - separation_cost: 0.0000e+00 - l1_weights_cost: 0.0015 - val_loss: 1.0853 - val_sparse_categorical_accuracy: 0.4008 - val_cluster_cost: 2.2111e-04 - val_separation_cost: 2.6723e-08 - val_l1_weights_cost: 0.0015\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 81s 102ms/step - loss: 1.0736 - sparse_categorical_accuracy: 0.4191 - cluster_cost: 2.0874e-04 - separation_cost: 3.5385e-06 - l1_weights_cost: 0.0015 - val_loss: 1.0852 - val_sparse_categorical_accuracy: 0.4015 - val_cluster_cost: 2.2672e-04 - val_separation_cost: 3.8481e-06 - val_l1_weights_cost: 0.0015\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 85s 107ms/step - loss: 1.0735 - sparse_categorical_accuracy: 0.4193 - cluster_cost: 2.3787e-04 - separation_cost: 3.3426e-05 - l1_weights_cost: 0.0015 - val_loss: 1.0851 - val_sparse_categorical_accuracy: 0.4015 - val_cluster_cost: 2.8343e-04 - val_separation_cost: 5.8630e-05 - val_l1_weights_cost: 0.0015\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 88s 110ms/step - loss: 1.0734 - sparse_categorical_accuracy: 0.4196 - cluster_cost: 2.6870e-04 - separation_cost: 6.5234e-05 - l1_weights_cost: 0.0015 - val_loss: 1.0851 - val_sparse_categorical_accuracy: 0.4013 - val_cluster_cost: 2.8281e-04 - val_separation_cost: 5.9405e-05 - val_l1_weights_cost: 0.0015\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "TRAINING STAGE = 9\n",
      "--------------------\n",
      "Running Prototype Push\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 16:22:27.296094: W tensorflow/core/util/tensor_slice_reader.cc:96] Could not open ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage8: FAILED_PRECONDITION: saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage8; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 6s 554ms/step\n",
      "9/9 [==============================] - 6s 531ms/step\n",
      "9/9 [==============================] - 7s 491ms/step\n",
      "Performing push of prototypes.\n",
      "Push complete.\n",
      "\n",
      "   conv_0 --> False\n",
      "   maxpooling_0 --> False\n",
      "   conv_1 --> False\n",
      "   maxpooling_1 --> False\n",
      "   conv_2 --> False\n",
      "   maxpooling_2 --> False\n",
      "   first_1x1_conv --> False\n",
      "   second_1x1_conv --> False\n",
      "   prototype --> False\n",
      "   final_weights --> True\n",
      "learning rate = 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| np.min(model.layers[-3].get_weights()[1]): -1.617821\n",
      "    np.max(model.layers[-3].get_weights()[1]): 5.0478024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/10\n",
      "799/799 [==============================] - 47s 57ms/step - loss: 1.0734 - sparse_categorical_accuracy: 0.4107 - cluster_cost: 9.7345e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 8.7656e-04 - val_loss: 1.0851 - val_sparse_categorical_accuracy: 0.3932 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 6.0896e-04\n",
      "Epoch 2/10\n",
      "799/799 [==============================] - 34s 42ms/step - loss: 1.0734 - sparse_categorical_accuracy: 0.4161 - cluster_cost: 9.7418e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 5.9251e-04 - val_loss: 1.0835 - val_sparse_categorical_accuracy: 0.3996 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 5.6980e-04\n",
      "Epoch 3/10\n",
      "799/799 [==============================] - 32s 40ms/step - loss: 1.0730 - sparse_categorical_accuracy: 0.4188 - cluster_cost: 9.7418e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 6.1682e-04 - val_loss: 1.0851 - val_sparse_categorical_accuracy: 0.3934 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 4.9246e-04\n",
      "Epoch 4/10\n",
      "799/799 [==============================] - 34s 42ms/step - loss: 1.0732 - sparse_categorical_accuracy: 0.4164 - cluster_cost: 9.7369e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 5.6486e-04 - val_loss: 1.0839 - val_sparse_categorical_accuracy: 0.4004 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 5.7320e-04\n",
      "Epoch 5/10\n",
      "799/799 [==============================] - 34s 42ms/step - loss: 1.0733 - sparse_categorical_accuracy: 0.4172 - cluster_cost: 9.7320e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 5.9043e-04 - val_loss: 1.0855 - val_sparse_categorical_accuracy: 0.3976 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 5.7974e-04\n",
      "Epoch 6/10\n",
      "799/799 [==============================] - 30s 38ms/step - loss: 1.0733 - sparse_categorical_accuracy: 0.4183 - cluster_cost: 9.7345e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 5.6876e-04 - val_loss: 1.0841 - val_sparse_categorical_accuracy: 0.4021 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 5.1511e-04\n",
      "Epoch 7/10\n",
      "799/799 [==============================] - 31s 39ms/step - loss: 1.0731 - sparse_categorical_accuracy: 0.4182 - cluster_cost: 9.7345e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 5.9421e-04 - val_loss: 1.0849 - val_sparse_categorical_accuracy: 0.3959 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 5.2458e-04\n",
      "Epoch 8/10\n",
      "799/799 [==============================] - 32s 41ms/step - loss: 1.0731 - sparse_categorical_accuracy: 0.4168 - cluster_cost: 9.7345e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 6.1607e-04 - val_loss: 1.0847 - val_sparse_categorical_accuracy: 0.3974 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 5.4091e-04\n",
      "Epoch 9/10\n",
      "799/799 [==============================] - 33s 41ms/step - loss: 1.0730 - sparse_categorical_accuracy: 0.4167 - cluster_cost: 9.7369e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 5.8194e-04 - val_loss: 1.0870 - val_sparse_categorical_accuracy: 0.4007 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 6.1461e-04\n",
      "Epoch 10/10\n",
      "799/799 [==============================] - 33s 41ms/step - loss: 1.0732 - sparse_categorical_accuracy: 0.4164 - cluster_cost: 9.7320e-05 - separation_cost: 0.0000e+00 - l1_weights_cost: 6.3049e-04 - val_loss: 1.0850 - val_sparse_categorical_accuracy: 0.3877 - val_cluster_cost: 1.0395e-04 - val_separation_cost: 0.0000e+00 - val_l1_weights_cost: 6.2495e-04\n",
      "Training complete.\n",
      "\n",
      "saving model and weights to ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./saved_models/vanc_fourteenday_precip/model_vanc_fourteenday_precip_stage9/assets\n"
     ]
    }
   ],
   "source": [
    "imp.reload(push_prototypes)\n",
    "NEPOCHS    = settings['nepochs']\n",
    "STAGE_LIST = (0,1,2,3,4,5,6,7,8,9)#range(len(NEPOCHS))#(1,2,3,4,5)#range(len(NEPOCHS))\n",
    "\n",
    "for stage in STAGE_LIST:\n",
    "    \n",
    "    print('--------------------')\n",
    "    print('TRAINING STAGE = ' + str(stage))\n",
    "    print('--------------------')\n",
    "\n",
    "    # load previously trained stage, unless it is the 0th stage\n",
    "    if(stage != 0):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage-1)\n",
    "#         model = common_functions.load_model(model_filename)\n",
    "        model.load_weights(model_filename)\n",
    "        \n",
    "    # learn layers (during even numbered stages)\n",
    "    if(stage % 2 == 0):\n",
    "        # train prototypes layers (and possibly CNN layers)\n",
    "        if(settings['pretrain']==False and settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(settings['train_cnn_in_stage'] == False or stage==0):\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "        elif(settings['train_cnn_in_stage'] == True):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        elif(stage >= settings['train_cnn_in_stage']):\n",
    "            model = network.set_trainable_layers(model, [True,True,True,False])            \n",
    "        else:\n",
    "            model = network.set_trainable_layers(model, [False,True,True,False])\n",
    "    else:\n",
    "        #.......................................................\n",
    "        # push the prototypes\n",
    "        #.......................................................        \n",
    "        model, push_info = push_prototypes.push(model, \n",
    "                                                [X_train,prototypes_of_correct_class_train], \n",
    "                                                prototypes_of_correct_class_train, \n",
    "                                                perform_push=True,\n",
    "                                                batch_size=BATCH_SIZE_PREDICT,\n",
    "                                                verbose=False,\n",
    "                                               )        \n",
    "        print('Push complete.\\n')            \n",
    "\n",
    "        # train weights layer only\n",
    "        model = network.set_trainable_layers(model, [False,False,False,True])        \n",
    "\n",
    "    #.......................................................\n",
    "    # compile the model\n",
    "    #.......................................................\n",
    "    if(stage>=settings['cut_lr_stage']):\n",
    "        lr_factor = 10.**(np.floor((stage-settings['cut_lr_stage']+2)/2))\n",
    "    else:\n",
    "        lr_factor = 1.\n",
    "    if(LR_INIT/lr_factor<settings['min_lr']):\n",
    "        lr_factor = LR_INIT/settings['min_lr']\n",
    "    print('learning rate = ' + str(np.asarray(LR_INIT/lr_factor,dtype='float32')))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=np.asarray(LR_INIT/lr_factor,dtype='float32'), \n",
    "        ),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics = metrics_list,\n",
    "    )\n",
    "#     model.summary()\n",
    "    ic(np.min(model.layers[-3].get_weights()[1]),np.max(model.layers[-3].get_weights()[1]))\n",
    "\n",
    "    #.......................................................\n",
    "    # train the model\n",
    "    #.......................................................\n",
    "    print('Training the model...')    \n",
    "    \n",
    "    tf.random.set_seed(RANDOM_SEED)   \n",
    "    np.random.seed(RANDOM_SEED)    \n",
    "    history = model.fit(\n",
    "        [X_train,prototypes_of_correct_class_train],\n",
    "        y_train,\n",
    "        validation_data=([[X_val,prototypes_of_correct_class_val]], [y_val]),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=NEPOCHS[stage],\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    print('Training complete.\\n')            \n",
    "        \n",
    "\n",
    "    # save the model at this training stage\n",
    "    model_filename = model_dir + 'model_' + EXP_NAME + '_stage' + str(stage)\n",
    "    common_functions.save_model(model, model_filename) \n",
    "    \n",
    "    #.......................................................\n",
    "    # plot results\n",
    "    #.......................................................  \n",
    "    try:\n",
    "        # plot loss history of the model\n",
    "        plots.plot_loss_history(history)\n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_loss_history_stage' + str(stage) + '.png', dpi=dpiFig)    \n",
    "        plt.close()\n",
    "\n",
    "        # plot the weights\n",
    "        plots.plot_weights(model, PROTOTYPES_PER_CLASS)    \n",
    "        plt.savefig(model_diagnostics_dir + EXP_NAME + '_weights_stage' + str(stage) + '.png', dpi=dpiFig)\n",
    "        plt.close()\n",
    "    except:\n",
    "        print('not making plots...')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24b663b0-f667-4172-a71a-7344b14b9590",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nicojg/Documents/Work/2021_Fall_IAI/Code/TLLTT/_main.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nicojg/Documents/Work/2021_Fall_IAI/Code/TLLTT/_main.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m Test\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Test' is not defined"
     ]
    }
   ],
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe303469",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"test\"\"test\"\"test\"\"test\"\"test\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3379bf0de2235d915f4d76244ddb70f86be36b0ba3c94a6c55c2320beeea2531"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('env-tf-cartopy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
